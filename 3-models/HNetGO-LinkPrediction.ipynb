{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQdQCfVLeeuz",
    "outputId": "7a395ebd-bf87-4710-c2c2-1573e873c6ce"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!conda list | grep dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.heterograph import DGLHeteroGraph\n",
    "from dgl.nn.functional import edge_softmax\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 显示所有输出结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('max_columns',1000)\n",
    "pd.set_option('max_row',300)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../0-data/3-models/\"\n",
    "OUT_DIR = \"./data\"\n",
    "\n",
    "INPUT_DATASET = {\n",
    "    \"human\": {\n",
    "        \"id\": \"9606\",\n",
    "        \"nets-min\": \"9606-nets-min.pkl\",\n",
    "        \"graphs-min\": \"9606-graphs-min.pkl\"\n",
    "    },\n",
    "    \"mouse\": {\n",
    "        \"id\": \"10090\",\n",
    "        \"nets-min\": \"10090-nets-min.pkl\",\n",
    "        \"graphs-min\": \"9606-graphs-min.pkl\"\n",
    "    }\n",
    "}\n",
    "\n",
    "sub_ontologies = {\n",
    "    \"bp\": \"GO:0008150\",\n",
    "    \"cc\": \"GO:0005575\",\n",
    "    \"mf\": \"GO:0003674\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Construct Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs(species: str, output: bool = True) -> dict:\n",
    "    \n",
    "    graph_path = BASE_DIR + INPUT_DATASET[species][\"graphs-min\"]\n",
    "\n",
    "    # load graphs\n",
    "    with open(graph_path, \"rb\") as f:\n",
    "        graphs = pickle.load(f)\n",
    "\n",
    "    print(\"graphs:\")\n",
    "    if output:\n",
    "        for branch, cur_graphs in graphs.items():\n",
    "            print(\"\\n\" + \"-\"*30, branch, \"-\"*30)\n",
    "            for freq, graph in cur_graphs.items():\n",
    "                print('\\033[1;36m' + branch + \": \" + freq + '\\033[0m')\n",
    "                print(graph)\n",
    "    else:\n",
    "        for branch, cur_graphs in graphs.items():\n",
    "            print(\"\\n\" + \"-\"*30, branch, \"-\"*30)\n",
    "            for freq, graph in cur_graphs.items():\n",
    "                print('\\033[1;36m' + freq + '\\033[0m', end = \" \")\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"human\"\n",
    "print(\"*\"*35 + species + \"*\"*35)\n",
    "graphs = load_graphs(species, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_cc = graphs['cc']['default']\n",
    "# graph_mf = graphs['mf']['default']\n",
    "# G = graph_cc\n",
    "G = graphs['bp']['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_by = G.edges(etype = 'annotated_by', form = 'all')\n",
    "annotated_by\n",
    "\n",
    "G.nodes['protein'].data['train_mask'] = torch.zeros(18560, dtype=torch.bool).bernoulli(0.9)\n",
    "G.nodes['protein'].data['test_mask'] = ~G.nodes['protein'].data['train_mask']\n",
    "\n",
    "masked = G.nodes['protein'].data['test_mask']\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build labels\n",
    "labels = torch.zeros(G.number_of_nodes('protein'), G.number_of_nodes('term'), dtype=torch.int8)\n",
    "\n",
    "for i in tqdm(range(len(annotated_by[0]))):\n",
    "    labels[annotated_by[0][i]][annotated_by[1][i]] = 1\n",
    "    \n",
    "G.nodes['protein'].data['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein seq features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_DIR + \"9606-avg-emb.pkl\", \"rb\") as f:\n",
    "    seq2emd = pickle.load(f)\n",
    "\n",
    "with open(BASE_DIR + \"9606-nets-min.pkl\", \"rb\") as f:\n",
    "    ppsn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2emd['Q66K14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppsn['id2node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2emb = list(map(lambda x: seq2emd[x], ppsn['id2node']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes['protein'].data['emb'] = torch.Tensor(id2emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes['protein'].data['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = G\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges = []\n",
    "for i in tqdm(range(len(annotated_by[2]))):\n",
    "    if not masked[annotated_by[0][i]]:\n",
    "        sub_edges.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {\n",
    "    'annotated_by': sub_edges,\n",
    "    'similar_with': G.edges(etype = 'similar_with', form = 'all')[2],\n",
    "    'annotate': sub_edges,\n",
    "    'son_of': G.edges(etype = 'son_of', form = 'all')[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.edge_subgraph(graph, edges, preserve_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = True\n",
    "for protein_id in tqdm(range(len(masked))):\n",
    "    if masked[protein_id]:\n",
    "        if protein_id in g.edges(etype = 'annotated_by', form = 'all')[0]:\n",
    "            print(protein_id)\n",
    "            tag = False\n",
    "if tag:\n",
    "    print(\"build sub_graph succ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = graph_cc\n",
    "G = graph\n",
    "node_dict = {}\n",
    "edge_dict = {}\n",
    "for ntype in G.ntypes:\n",
    "    node_dict[ntype] = len(node_dict)\n",
    "for etype in G.etypes:\n",
    "    edge_dict[etype] = len(edge_dict)\n",
    "    G.edges[etype].data['id'] = torch.ones(G.number_of_edges(etype), dtype=torch.long) * edge_dict[etype] \n",
    "\n",
    "#     Random initialize input feature\n",
    "for ntype in G.ntypes:\n",
    "    emb = nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), 1024), requires_grad = False)\n",
    "    nn.init.xavier_uniform_(emb)\n",
    "    G.nodes[ntype].data['inp'] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes['protein'].data['inp'] = G.nodes['protein'].data['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes['protein'].data['inp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KISCQ6SpdGAD"
   },
   "outputs": [],
   "source": [
    "class HNetGOLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 out_dim,\n",
    "                 node_dict,\n",
    "                 edge_dict,\n",
    "                 n_heads,\n",
    "                 dropout = 0.2,\n",
    "                 use_norm = False):\n",
    "        super(HNetGOLayer, self).__init__()\n",
    "\n",
    "        self.in_dim        = in_dim\n",
    "        self.out_dim       = out_dim\n",
    "        self.node_dict     = node_dict\n",
    "        self.edge_dict     = edge_dict\n",
    "        self.num_types     = len(node_dict)\n",
    "        self.num_relations = len(edge_dict)\n",
    "        self.total_rel     = self.num_types * self.num_relations * self.num_types\n",
    "        self.n_heads       = n_heads\n",
    "        self.d_k           = out_dim // n_heads\n",
    "        self.sqrt_dk       = math.sqrt(self.d_k)\n",
    "        self.att           = None\n",
    "\n",
    "        self.k_linears   = nn.ModuleList()\n",
    "        self.q_linears   = nn.ModuleList()\n",
    "        self.v_linears   = nn.ModuleList()\n",
    "        self.a_linears   = nn.ModuleList()\n",
    "        self.norms       = nn.ModuleList()\n",
    "        self.use_norm    = use_norm\n",
    "\n",
    "        for t in range(self.num_types):\n",
    "            self.k_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.q_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.v_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.a_linears.append(nn.Linear(out_dim,  out_dim))\n",
    "            if use_norm:\n",
    "                self.norms.append(nn.LayerNorm(out_dim))\n",
    "\n",
    "        self.relation_pri   = nn.Parameter(torch.ones(self.num_relations, self.n_heads))\n",
    "        self.relation_att   = nn.Parameter(torch.Tensor(self.num_relations, n_heads, self.d_k, self.d_k))\n",
    "        self.relation_msg   = nn.Parameter(torch.Tensor(self.num_relations, n_heads, self.d_k, self.d_k))\n",
    "        self.skip           = nn.Parameter(torch.ones(self.num_types))\n",
    "        self.drop           = nn.Dropout(dropout)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.relation_att)\n",
    "        nn.init.xavier_uniform_(self.relation_msg)\n",
    "\n",
    "    def forward(self, G, h):\n",
    "        with G.local_scope():\n",
    "            node_dict, edge_dict = self.node_dict, self.edge_dict\n",
    "            for srctype, etype, dsttype in G.canonical_etypes:\n",
    "                sub_graph = G[srctype, etype, dsttype]\n",
    "\n",
    "                k_linear = self.k_linears[node_dict[srctype]]\n",
    "                v_linear = self.v_linears[node_dict[srctype]]\n",
    "                q_linear = self.q_linears[node_dict[dsttype]]\n",
    "\n",
    "                k = k_linear(h[srctype]).view(-1, self.n_heads, self.d_k)\n",
    "                v = v_linear(h[srctype]).view(-1, self.n_heads, self.d_k)\n",
    "                q = q_linear(h[dsttype]).view(-1, self.n_heads, self.d_k)\n",
    "\n",
    "                e_id = self.edge_dict[etype]\n",
    "\n",
    "                relation_att = self.relation_att[e_id]\n",
    "                relation_pri = self.relation_pri[e_id]\n",
    "                relation_msg = self.relation_msg[e_id]\n",
    "\n",
    "                k = torch.einsum(\"bij,ijk->bik\", k, relation_att)\n",
    "                v = torch.einsum(\"bij,ijk->bik\", v, relation_msg)\n",
    "\n",
    "                sub_graph.srcdata['k'] = k\n",
    "                sub_graph.dstdata['q'] = q\n",
    "                sub_graph.srcdata['v'] = v\n",
    "\n",
    "                sub_graph.apply_edges(fn.v_dot_u('q', 'k', 't'))\n",
    "                attn_score = sub_graph.edata.pop('t').sum(-1) * relation_pri / self.sqrt_dk\n",
    "                attn_score = edge_softmax(sub_graph, attn_score, norm_by='dst')\n",
    "\n",
    "                sub_graph.edata['t'] = attn_score.unsqueeze(-1)\n",
    "\n",
    "            G.multi_update_all({etype : (fn.u_mul_e('v', 't', 'm'), fn.sum('m', 't')) \\\n",
    "                                for etype in edge_dict}, cross_reducer = 'mean')\n",
    "\n",
    "            new_h = {}\n",
    "            for ntype in G.ntypes:\n",
    "                n_id = node_dict[ntype]\n",
    "                alpha = torch.sigmoid(self.skip[n_id])\n",
    "                t = G.nodes[ntype].data['t'].view(-1, self.out_dim)\n",
    "                trans_out = self.drop(self.a_linears[n_id](t))\n",
    "                trans_out = trans_out * alpha + h[ntype] * (1-alpha)\n",
    "                if self.use_norm:\n",
    "                    new_h[ntype] = self.norms[n_id](trans_out)\n",
    "                else:\n",
    "                    new_h[ntype] = trans_out\n",
    "            return new_h\n",
    "\n",
    "class HNetGO(nn.Module):\n",
    "    def __init__(self, G, node_dict, edge_dict, n_inp, n_hid, n_out, n_layers, n_heads, use_norm = True):\n",
    "        super(HNetGO, self).__init__()\n",
    "        self.node_dict = node_dict\n",
    "        self.edge_dict = edge_dict\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.n_inp = n_inp\n",
    "        self.n_hid = n_hid\n",
    "        self.n_out = n_out\n",
    "        self.n_layers = n_layers\n",
    "        self.adapt_ws  = nn.ModuleList()\n",
    "        for t in range(len(node_dict)):\n",
    "            self.adapt_ws.append(nn.Linear(n_inp,  n_hid))\n",
    "        for _ in range(n_layers):\n",
    "            self.gcs.append(HNetGOLayer(n_hid, n_hid, node_dict, edge_dict, n_heads, use_norm = use_norm))\n",
    "        self.out = nn.Linear(n_hid, n_out)\n",
    "\n",
    "    def forward(self, G):\n",
    "        h = {}\n",
    "        for ntype in G.ntypes:\n",
    "            n_id = self.node_dict[ntype]\n",
    "            h[ntype] = F.gelu(self.adapt_ws[n_id](G.nodes[ntype].data['inp']))\n",
    "        for i in range(self.n_layers):\n",
    "            h = self.gcs[i](G, h)\n",
    "#         return torch.sigmoid(self.out(h[out_key]))\n",
    "        return h\n",
    "    \n",
    "# Link Prediction\n",
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f = nn.Linear(1024, 1024)\n",
    "        \n",
    "    def forward(self, graph, h, etype):\n",
    "        # h contains the node representations for each node type computed from\n",
    "        # the GNN defined in the previous section (Section 5.1).\n",
    "        return torch.sigmoid(torch.mm(self.f(h['protein']), h['term'].t()))\n",
    "\n",
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, _, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    neg_dst = torch.randint(0, graph.number_of_nodes(vtype), (len(src) * k,)).int().to(device)\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.number_of_nodes(ntype) for ntype in graph.ntypes})\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.hnetgo = model\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, neg_g, etype):\n",
    "        global h\n",
    "        h = self.hnetgo(g)\n",
    "#         print(h)\n",
    "        return self.pred(g, h, etype), self.pred(neg_g, h, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = nn.Linear(1024, 1024).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.sigmoid(torch.mm(f(h['protein']), h['term'].t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RcEXYVhdwRS"
   },
   "outputs": [],
   "source": [
    "def calculate_performance(actual, pred_prob, threshold=0.4, average='micro'):\n",
    "    pred_lable = []\n",
    "    for l in range(len(pred_prob)):\n",
    "        eachline = (pred_prob[l].cpu().detach().numpy() > threshold).astype(np.int)\n",
    "        eachline = eachline.tolist()\n",
    "        pred_lable.append(eachline)\n",
    "    f_score = f1_score(actual.cpu().detach().numpy(), np.array(pred_lable), average=average)\n",
    "    recall = recall_score(actual.cpu().detach().numpy(), np.array(pred_lable), average=average)\n",
    "    precision = precision_score(actual.cpu().detach().numpy(), np.array(pred_lable), average=average)\n",
    "    fpr, tpr, th = roc_curve(actual.cpu().detach().numpy().flatten(),pred_prob.cpu().detach().numpy().flatten(), pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    aupr=cacul_aupr(actual.cpu().detach().numpy().flatten(),pred_prob.cpu().detach().numpy().flatten())\n",
    "    return f_score, precision, recall, auc_score, aupr\n",
    "\n",
    "def cacul_aupr(lables, pred):\n",
    "    precision, recall, _thresholds = metrics.precision_recall_curve(lables, pred)\n",
    "    aupr = metrics.auc(recall, precision)\n",
    "    return aupr\n",
    "\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "def train(model, G):\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    train_step = 0\n",
    "    lossF = nn.BCELoss()\n",
    "    fmax = 0\n",
    "    p_r_curve = []\n",
    "    \n",
    "    for epoch in np.arange(2000) + 1:\n",
    "        print(\"Epoch: %d\" % (epoch))\n",
    "        model.train()\n",
    "        print(\"train succ\")\n",
    "        negative_graph = construct_negative_graph(G, 1, ('protein', 'annotated_by', 'term'))\n",
    "        global pos_score, logits, neg_score\n",
    "        pos_score, neg_score = model(G, negative_graph, ('protein', 'annotated_by', 'term'))\n",
    "        # The loss is computed only for labeled nodes.\n",
    "        logits = pos_score\n",
    "        loss = lossF(logits[train_mask], labels[train_mask])\n",
    "#         loss = - torch.sum(torch.log(pos_score+0.01)) - torch.sum(torch.log(1-neg_score+0.01))\n",
    "#         loss = (1 - pos_score + neg_score).clamp(min=0).mean()\n",
    "        if epoch % 1 == 0:\n",
    "            model.eval()\n",
    "#             logits, _ = model(G, negative_graph, ('protein', 'annotated_by', 'term'))\n",
    "            with torch.no_grad():\n",
    "                f1, recall, prescision, auc_score, aupr = calculate_performance(labels[test_mask], logits[test_mask])\n",
    "                p_r_curve.append([f1, recall, prescision, auc_score, aupr])\n",
    "                if f1>fmax:\n",
    "                    fmax = f1\n",
    "                    torch.save(model.state_dict(), './data/models/HNetGO_Link_{}_{}.pkl'.format(f1, epoch))\n",
    "                    with open( \"./prCurve_Model1\", 'bw') as f:\n",
    "                        pickle.dump(p_r_curve, f)\n",
    "\n",
    "                # pred   = logits.argmax(1).cpu()\n",
    "                # train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "                # val_acc   = (pred[val_idx]   == labels[val_idx]).float().mean()\n",
    "                # test_acc  = (pred[test_idx]  == labels[test_idx]).float().mean()\n",
    "                # if best_val_acc < val_acc:\n",
    "                #     best_val_acc = val_acc\n",
    "                #     best_test_acc = test_acc\n",
    "                print('Epoch: %d LR: %.5f Loss %.4f, f1: %.4f, racall: %.4f, prescision: %.4f, auc: %.4f, aupr: %.4f' % (\n",
    "                    epoch,\n",
    "                    optimizer.param_groups[0]['lr'], \n",
    "                    loss.item(),\n",
    "                    f1, recall, prescision, auc_score, aupr\n",
    "                ))\n",
    "            \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_step += 1\n",
    "        scheduler.step(train_step)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSAhAd09d5kZ",
    "outputId": "c349fb22-259f-462c-f682-7975864e98be"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model = HNetGO(G,\n",
    "            node_dict, edge_dict,\n",
    "            n_inp=1024,\n",
    "            n_hid=1024,\n",
    "            n_out=labels.shape[1],\n",
    "            n_layers=2,\n",
    "            n_heads=4,\n",
    "            use_norm = True).to(device)\n",
    "model = Model(model).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, total_steps=10000, max_lr = 0.001)\n",
    "print('Training HNetGO with #param: %d' % (get_n_params(model)))\n",
    "G = G.to(device)\n",
    "labels = G.nodes['protein'].data['labels'].float()\n",
    "train_mask = G.nodes['protein'].data['train_mask']\n",
    "test_mask = G.nodes['protein'].data['test_mask']\n",
    "train(model, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thresholds = list(map(lambda x:round(x*0.01,2), list(range(1,100))))\n",
    "Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_graph = construct_negative_graph(G, 1, ('protein', 'annotated_by', 'term'))\n",
    "logits, neg_score = model(G, negative_graph, ('protein', 'annotated_by', 'term'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_best_scores = []\n",
    "each_best_fcore = 0\n",
    "score_dict = {}\n",
    "for i in tqdm(range(len(Thresholds))):\n",
    "    f1, recall, precision, auc_score, aupr  = calculate_performance(labels[test_mask], logits[test_mask], threshold=Thresholds[i])\n",
    "    if f1 > each_best_fcore:\n",
    "        each_best_fcore = f1\n",
    "        each_best_scores = [Thresholds[i], f1, recall, precision, auc_score, aupr]\n",
    "    scores = [f1, recall, precision, auc_score]\n",
    "    score_dict[Thresholds[i]] = scores\n",
    "each_best_scores"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
